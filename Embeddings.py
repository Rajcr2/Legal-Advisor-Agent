import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="pdfplumber")

import psycopg2
import chromadb
import requests
import pdfplumber
import time
import io
from langchain.text_splitter import CharacterTextSplitter

OLLAMA_URL = "http://localhost:11434/api/embeddings"
MODEL_NAME = "llama3"

def get_llama_embedding(texts):
    embeddings = []
    for text in texts:
        response = requests.post(OLLAMA_URL, json={"model": MODEL_NAME, "prompt": text})
        if response.status_code == 200:
            embeddings.append(response.json().get("embedding", []))
        else:
            print(f"‚ùå Error fetching embedding for text: {response.text}")
            embeddings.append([])
    return embeddings

def get_pdf_data():
    conn = psycopg2.connect(
        dbname="agent_db",
        user="postgres",
        password="pass",
        host="localhost",
        port="5432"
    )

def get_existing_sources(collection):
    try:
        results = collection.get(include=["metadatas"])
        sources = {meta["source"] for meta in results["metadatas"]}
        return sources
    except Exception:
        return set()

def generate_embeddings():
    print("üîÑ Generating embeddings incrementally...")

    pdf_data_list = get_pdf_data()
    if not pdf_data_list:
        print("‚ùå No documents found in PostgreSQL.")
        return

    client = chromadb.PersistentClient(path="./chroma_db_agent")
    collection = client.get_or_create_collection("llama_test_embeddings")
    existing_sources = get_existing_sources(collection)

    doc_count = 0
    for pdf_name, pdf_binary in pdf_data_list:
        if pdf_name in existing_sources:
            print(f"‚úÖ Vector embeddings already exist for '{pdf_name}'. Skipping.")
            continue

        extracted_text = []
        pdf_stream = io.BytesIO(pdf_binary)
        with pdfplumber.open(pdf_stream) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    extracted_text.append(text)

        if not extracted_text:
            print(f"‚ö†Ô∏è No text found in '{pdf_name}'. Skipping.")
            continue

        combined_text = "\n".join(extracted_text)
        text_splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text(combined_text)

        if not chunks:
            print(f"‚ö†Ô∏è No valid text chunks for '{pdf_name}'. Skipping.")
            continue

        batch_size = 5
        total_chunks = len(chunks)
        embeddings = []  # Initialize embeddings inside the loop

        print(f"\n'{pdf_name}' split into {total_chunks} chunks. Processing in {total_chunks // batch_size + 1} batches...\n")

        for i in range(0, total_chunks, batch_size):
            batch = chunks[i:i + batch_size]
            print(f"‚è≥ Processing batch {i // batch_size + 1}/{(total_chunks // batch_size) + 1} for '{pdf_name}'...")
            start_time = time.time()

            try:
                batch_embeddings = get_llama_embedding(batch)
                if len(batch_embeddings) == len(batch):  # Ensure embedding length matches batch size
                    embeddings.extend(batch_embeddings)
                else:
                    print(f"‚ö†Ô∏è Skipping batch {i // batch_size + 1} due to embedding mismatch.")
            except Exception as e:
                print(f"‚ùå Error in embedding batch {i // batch_size + 1}: {e}")
                continue

            print(f"‚úÖ Batch {i // batch_size + 1} completed in {time.time() - start_time:.2f}s.\n")

def retrieve_relevant_laws(query):
    try:
        client = chromadb.PersistentClient(path="./chroma_db_agent")
        collection = client.get_collection("llama_test_embeddings")
        query_embedding = get_llama_embedding([query])
        if not query_embedding or len(query_embedding[0]) == 0:
            return ["‚ùå Query embedding failed."]
        results = collection.query(query_embeddings=query_embedding, n_results=3)
        return results["documents"][0] if "documents" in results else []
    except Exception as e:
        print(f"‚ùå Error during retrieval: {e}")
        return ["Error retrieving legal information."]

if __name__ == "__main__":
    generate_embeddings()
